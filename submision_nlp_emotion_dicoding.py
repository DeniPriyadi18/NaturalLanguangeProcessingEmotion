# -*- coding: utf-8 -*-
"""SUBMISION NLP EMOTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D-dfPgPMoGNSzx0fRhNouppflpYAJmri

<h1><Br> NAMA : DENI PRIYADI
<h1> NIM :191410038
<h1> ALAMAT : KABUPATEN MAJALENGKA

<h1>Menyambungkan ke penyimpanan google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""<h1> IMPORT LIBRARY YANG DIBUTUHKAN"""

import zipfile
import tensorflow as tf
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

"""<h1> EKSTRAK DATASET YANG BERASAL DARI GOOGLE DRIVE

<p> Dataset dapat diunduh melalui link di berikut : https://drive.google.com/file/d/1H1Ore50nTq8bYu23HBTFrJl2z6ONUR-G/view?usp=sharing
"""

Target_file = '/content/drive/MyDrive/DICODING/DATASET/emotion.zip'

extracting = zipfile.ZipFile (Target_file, 'r')
extracting.extractall('/content/drive/MyDrive/DICODING/DATASET/emotion')
extracting.close()

"""<h1>MENGUBAH DATASET BERBENTUK CSV MENJADI SEBUAH DATAFRAME

"""

df = pd.read_csv('/content/drive/MyDrive/DICODING/DATASET/emotion/Emotion_classify_Data.csv')
df.info()

df.head()

df.tail()

"""<h1> ONE HOT ENCODING

"""

kategori = pd.get_dummies(df.Emotion)
new_df = pd.concat([df, kategori], axis = 1)

new_df.head()

new_df = new_df.drop(columns = 'Emotion')
new_df

"""<h1>MEMISAHKAN ATRIBUT DENGAN LABEL"""

x = new_df['Comment'].values
y = new_df[['anger', 'fear', 'joy']].values

"""<h1> SPLIT DATASET
<p> Dataset menggunakan ratio 8:2 di mana untuk data train sebesar 80% dan untuk validasinya sebesar 20%
"""

x_train, X_test, y_train, Y_test = train_test_split(x, y, test_size = 0.2)

"""<h1>TOKENISASI TEKS

"""

tokenizer = Tokenizer(num_words = 10000, oov_token ='<OOV>')
tokenizer.fit_on_texts(x_train)

"""<h1> TOKENISASI TO SEQUENCE"""

s_train = tokenizer.texts_to_sequences(x_train)
s_test = tokenizer.texts_to_sequences(X_test)

"""<h1> PADDING TEKS"""

pad_train = pad_sequences(s_train,
                          maxlen = 50)
pad_test = pad_sequences(s_test,
                         maxlen = 50)

"""<h1> ARSITEKTUR MODEL"""

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=10000,output_dim=16),
    tf.keras.layers.LSTM(128, dropout = 0.2 , recurrent_dropout= 0.2),
    tf.keras.layers.Dense(3,  activation = 'softmax')
])

model.summary()

"""<h1> FUNGSI CALLBACKS"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch,logs= {}):
    if(logs.get('accuracy') >= 0.95):
      print ("accuracy sudah mencapai 95%")
      self.model.stop_training = True

model.compile (loss = 'categorical_crossentropy',
               optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001),
               metrics = ['accuracy'])

"""<h1> Latih Model"""

history = model.fit (
    pad_train,
    y_train,
    epochs=25,
    validation_data= (pad_test, Y_test),
    verbose = 2,
    batch_size = 128,
    callbacks = [myCallback()]
)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib.image as mimg
import matplotlib.pyplot as plt

acc = (history.history['accuracy'])
val_acc = (history.history['val_accuracy'])
loss = (history.history['loss'])
val_loss = (history.history['val_loss'])

plt.figure(figsize = (16,8))
plt.subplot(1,2,1)

plt.plot(acc, label = 'Akurasi Training')
plt.plot(val_acc, label = 'Akurasi validasi')
plt.title = ('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('accuracy')
plt.legend(loc = 'upper left')

plt.subplot(1,2,2)
plt.plot(loss, label = 'Loss Training')
plt.plot(val_loss, label = 'Loss validasi')
plt.title = ('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('loss')
plt.legend(loc = 'upper left')

plt.show()

